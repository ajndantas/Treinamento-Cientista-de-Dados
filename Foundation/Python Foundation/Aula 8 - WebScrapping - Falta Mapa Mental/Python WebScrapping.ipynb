{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Capturando requests com módulo request nativo do Python\n",
    "'''\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = 'https://pythonscraping.com/pages/page1.html'\n",
    "\n",
    "codHTML = urlopen(url)\n",
    "\n",
    "codHTML.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Capturando requests com módulo requests\n",
    "'''\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://pythonscraping.com/pages/page1.html'\n",
    "\n",
    "codeHTML = requests.get(url)\n",
    "\n",
    "codeHTML.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m     10\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.wikipedia.org\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 12\u001b[0m codHTML \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# BeautifulSoup(HTML Code,parser). lxml é o melhor parser. \u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\u001b[39;00m\n\u001b[0;32m     17\u001b[0m bs \u001b[38;5;241m=\u001b[39m BeautifulSoup(codHTML,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Capturando requests com módulo BeautifulSoup para o site \n",
    "\n",
    "    www.wikipedia.org\n",
    "'''\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.wikipedia.org'\n",
    "\n",
    "codHTML = urlopen(url)\n",
    "\n",
    "# BeautifulSoup(HTML Code,parser). lxml é o melhor parser. \n",
    "# Documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\n",
    "\n",
    "bs = BeautifulSoup(codHTML,'lxml')\n",
    "\n",
    "print(bs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O BeautifulSoup, transforma o HTML em tag objects que podem ser acessados da seguinte forma:\n",
    "# BeautifulSoup Object.<HTML tag>\n",
    "\n",
    "type(bs.a) # Mostra o tipo de objeto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"link-box\" data-slogan=\"The Free Encyclopedia\" href=\"//en.wikipedia.org/\" id=\"js-link-box-en\" title=\"English — Wikipedia — The Free Encyclopedia\">\n",
      "<strong>English</strong>\n",
      "<small><bdi dir=\"ltr\">6 284 000+</bdi> <span>articles</span></small>\n",
      "</a>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Acessando as tags com BeautifulSoup\n",
    "'''\n",
    "\n",
    "# Acessando a primeira ocorrência do tag object\n",
    "tag = bs.a\n",
    "\n",
    "print(tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//en.wikipedia.org/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acesando o atributo da tag\n",
    "tag['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'js-link-box-en',\n",
       " 'href': '//en.wikipedia.org/',\n",
       " 'title': 'English — Wikipedia — The Free Encyclopedia',\n",
       " 'class': ['link-box'],\n",
       " 'data-slogan': 'The Free Encyclopedia'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dicionário com os atributos da tag\n",
    "tag.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"central-textlogo\" style=\"font-size: 1em;\">\n",
       "<img alt=\"Wikipedia\" class=\"central-featured-logo\" height=\"183\" src=\"portal/wikipedia.org/assets/img/Wikipedia-logo-v2.png\" srcset=\"portal/wikipedia.org/assets/img/Wikipedia-logo-v2@1.5x.png 1.5x, portal/wikipedia.org/assets/img/Wikipedia-logo-v2@2x.png 2x\" width=\"200\"/>\n",
       "<h1 class=\"central-textlogo-wrapper\">\n",
       "<span class=\"central-textlogo__image sprite svg-Wikipedia_wordmark\">\n",
       "Wikipedia\n",
       "</span>\n",
       "<strong class=\"jsl10n localized-slogan\" data-jsl10n=\"slogan\">The Free Encyclopedia</strong>\n",
       "</h1>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtro: list\n",
    "bs.find(['h1','div'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<strong class=\"jsl10n localized-slogan\" data-jsl10n=\"slogan\">The Free Encyclopedia</strong>\n",
      "<title>IMDb Top 250 - IMDb</title>\n"
     ]
    }
   ],
   "source": [
    "#Filtro: Expressão Regular\n",
    "import re\n",
    "\n",
    "print(bs.find(re.compile('title')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m     15\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.wikipedia.org\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 17\u001b[0m codHTML \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# BeautifulSoup(HTML Code,parser). lxml é o melhor parser. \u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\u001b[39;00m\n\u001b[0;32m     22\u001b[0m bs \u001b[38;5;241m=\u001b[39m BeautifulSoup(codHTML,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "    Method signature:   find(name, attrs, recursive, **kwargs)\n",
    "\n",
    "                        def values:\n",
    "                        name = None, attrs = {}, recursive = True, text = None\n",
    "                        **kwargs -> tamanho variável. Argumentos Chave = Atributos da tag e seus valores\n",
    "\n",
    "    Retorna a tag aonde se encontra a string\n",
    "'''\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.wikipedia.org'\n",
    "\n",
    "codHTML = urlopen(url)\n",
    "\n",
    "# BeautifulSoup(HTML Code,parser). lxml é o melhor parser. \n",
    "# Documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\n",
    "\n",
    "bs = BeautifulSoup(codHTML,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"central-textlogo-wrapper\">\n",
      "<span class=\"central-textlogo__image sprite svg-Wikipedia_wordmark\">\n",
      "Wikipedia\n",
      "</span>\n",
      "<strong class=\"jsl10n localized-slogan\" data-jsl10n=\"slogan\">The Free Encyclopedia</strong>\n",
      "</h1>\n"
     ]
    }
   ],
   "source": [
    "# Usando texto\n",
    "h1 = bs.find('h1')\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>, <link href=\"/static/favicon/wikipedia.ico\" rel=\"shortcut icon\"/>, <link href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\"/>, <link href=\"//upload.wikimedia.org\" rel=\"preconnect\"/>]\n",
      "\n",
      "\n",
      "[<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bs.find_all('link'))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(bs.find_all('link',limit = 1)) # Aqui está fazendo o mesmo papel do find()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de elementos-tags link encontrados = 4\n"
     ]
    }
   ],
   "source": [
    "print('Número total de elementos-tags link encontrados = {}'.format(len(bs.find_all('link'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m     16\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.wikipedia.org\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 18\u001b[0m codHTML \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m bs \u001b[38;5;241m=\u001b[39m BeautifulSoup(codHTML,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Utilizando os elementos do HTML class e id para fazer extração.\n",
    "\n",
    "    A maioria dos sites os contém.\n",
    "\n",
    "    Searching by CSS class\n",
    "\n",
    "        It’s very useful to search for a tag that has a certain CSS class, but the \n",
    "        name of the CSS attribute, “class”, is a reserved word in Python. Using class \n",
    "        as a keyword argument will give you a syntax error. As of Beautiful Soup 4.1.2,        you can search by CSS class using the keyword argument class_:\n",
    "'''\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.wikipedia.org'\n",
    "\n",
    "codHTML = urlopen(url)\n",
    "\n",
    "bs = BeautifulSoup(codHTML,'lxml')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    O objetivo será fazer um scrapping do logo da Terra. \n",
    "    Antes de executar o código, usar a ferramenta de inspeção do código (CTRL + Shift + C no Chrome), e selecionar o logo central do planeta Terra no site da Wikipedia\n",
    "\n",
    "    Têm-se a saída abaixo na ferramenta de inspeção:\n",
    "\n",
    "    <img class=\"central-featured-logo\" src=\"portal/wikipedia.org/assets/img/Wikipedia-logo-v2.png\" srcset=\"portal/wikipedia.org/assets/img/Wikipedia-logo-v2@1.5x.png 1.5x, portal/wikipedia.org/assets/img/Wikipedia-logo-v2@2x.png 2x\" width=\"200\" height=\"183\" alt=\"Wikipedia\">\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Wikipedia\" class=\"central-featured-logo\" height=\"183\" src=\"portal/wikipedia.org/assets/img/Wikipedia-logo-v2.png\" srcset=\"portal/wikipedia.org/assets/img/Wikipedia-logo-v2@1.5x.png 1.5x, portal/wikipedia.org/assets/img/Wikipedia-logo-v2@2x.png 2x\" width=\"200\"/>\n"
     ]
    }
   ],
   "source": [
    "print(bs.find(class_='central-featured-logo')) # O _ foi para diferenciar da \n",
    "                                               # palavra reservada class. Isso é so                                                # para o BeutifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"link-box\" data-slogan=\"A enciclopédia livre\" href=\"//pt.wikipedia.org/\" id=\"js-link-box-pt\" title=\"Português — Wikipédia — A enciclopédia livre\">\n",
      "<strong>Português</strong>\n",
      "<small><bdi dir=\"ltr\">1 048 000+</bdi> <span>artigos</span></small>\n",
      "</a>\n"
     ]
    }
   ],
   "source": [
    "# Acessando atributos da tag. Usando keyword arguments *kwargs\n",
    "\n",
    "'''\n",
    "    O objetivo será obter o texto \"Português\" e seus números de artigos nessa língua que se encontra ao lado do globo.\n",
    "\n",
    "    - Selecionar com a ferramenta de inspeção de código, o trecho \"Português\", \n",
    "    que se encontra ao lado do globo\n",
    "    \n",
    "    Trecho da ferramenta de inspeção de código:\n",
    "\n",
    "    <div class=\"central-featured-lang lang1\" lang=\"pt\" dir=\"ltr\">\n",
    "        <a id=\"js-link-box-pt\" href=\"//pt.wikipedia.org/\" title=\"Português — Wikipédia — A enciclopédia livre\" class=\"link-box\" data-slogan=\"A enciclopédia livre\">\n",
    "            <strong>Português</strong>\n",
    "            <small>\n",
    "                    <bdi dir=\"ltr\">1&nbsp;048&nbsp;000+</bdi> <span>artigos</span>\n",
    "            </small>\n",
    "        </a>\n",
    "    </div>\n",
    "'''\n",
    "\n",
    "# Dessa forma, obtemos a tag(s) com esse atributo\n",
    "print(bs.find(id='js-link-box-pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Português\n",
      "1 048 000+ artigos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pegar tudo que é texto, que esteja dentro da tag, que contém o argumento chave id\n",
    "\n",
    "print(bs.find(id='js-link-box-pt').get_text()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<strong class=\"jsl10n localized-slogan\" data-jsl10n=\"slogan\">The Free Encyclopedia</strong>, <strong>English</strong>, <strong>Español</strong>, <strong>日本語</strong>, <strong>Deutsch</strong>, <strong>Русский</strong>, <strong>Français</strong>, <strong>Italiano</strong>, <strong>中文</strong>, <strong>Português</strong>, <strong>Polski</strong>, <strong class=\"jsl10n\" data-jsl10n=\"app-links.title\">\n",
      "<a class=\"jsl10n\" data-jsl10n=\"app-links.url\" href=\"https://en.wikipedia.org/wiki/List_of_Wikipedia_mobile_applications\">\n",
      "Download Wikipedia for Android or iOS\n",
      "</a>\n",
      "</strong>]\n",
      "\n",
      "\n",
      "Strong tag Português:  <strong>Português</strong>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Usando selectores CSS, tags dentro de tags. Navegando na árvore HTML. Para isso, usar o método select, que nos retorna uma lista\n",
    "\n",
    "    Aqui, selecionaremos todas as tags 'strong' dentro das tags 'divs' \n",
    "'''\n",
    "strongtag = bs.select('div strong')\n",
    "print(strongtag) \n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Strong tag Português: \",strongtag[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<input name=\"family\" type=\"hidden\" value=\"wikipedia\"/>, <input id=\"hiddenLanguageInput\" name=\"language\" type=\"hidden\" value=\"en\"/>, <input accesskey=\"F\" autocomplete=\"off\" autofocus=\"autofocus\" dir=\"auto\" id=\"searchInput\" name=\"search\" size=\"20\" type=\"search\"/>, <input name=\"go\" type=\"hidden\" value=\"Go\"/>]\n"
     ]
    }
   ],
   "source": [
    "print(bs.select('div form input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"footer-sidebar\">\n",
      "<div class=\"footer-sidebar-content\">\n",
      "<div class=\"footer-sidebar-icon sprite svg-Wikimedia-logo_black\">\n",
      "</div>\n",
      "<div class=\"footer-sidebar-text jsl10n\" data-jsl10n=\"footer-description\">\n",
      "Wikipedia is hosted by the <a href=\"//wikimediafoundation.org/\">Wikimedia Foundation</a>, a non-profit organization that also hosts a range of other projects.\n",
      "</div>\n",
      "</div>\n",
      "</div>, <div class=\"footer-sidebar app-badges\">\n",
      "<div class=\"footer-sidebar-content\">\n",
      "<div class=\"footer-sidebar-text\">\n",
      "<div class=\"footer-sidebar-icon sprite svg-wikipedia_app_tile\"></div>\n",
      "<strong class=\"jsl10n\" data-jsl10n=\"app-links.title\">\n",
      "<a class=\"jsl10n\" data-jsl10n=\"app-links.url\" href=\"https://en.wikipedia.org/wiki/List_of_Wikipedia_mobile_applications\">\n",
      "Download Wikipedia for Android or iOS\n",
      "</a>\n",
      "</strong>\n",
      "<p class=\"jsl10n\" data-jsl10n=\"app-links.description\">\n",
      "Save your favorite articles to read offline, sync your reading lists across devices and customize your reading experience with the official Wikipedia app.\n",
      "</p>\n",
      "<ul>\n",
      "<li class=\"app-badge app-badge-android\">\n",
      "<a href=\"//play.google.com/store/apps/details?id=org.wikipedia&amp;referrer=utm_source%3Dportal%26utm_medium%3Dbutton%26anid%3Dadmob\" target=\"_blank\">\n",
      "<span class=\"sprite svg-badge_google_play_store\">\n",
      "</span></a>\n",
      "</li>\n",
      "<li class=\"app-badge app-badge-ios\">\n",
      "<a href=\"//itunes.apple.com/app/apple-store/id324715238?pt=208305&amp;ct=portal&amp;mt=8\" target=\"_blank\">\n",
      "<span class=\"sprite svg-badge_ios_app_store\">\n",
      "</span></a>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Outra maneira de acessar o elemento class. Usando select\n",
    "'''\n",
    "\n",
    "print(bs.select('.footer-sidebar'))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"central-featured-lang lang9\" dir=\"ltr\" lang=\"pt\">\n",
      "<a class=\"link-box\" data-slogan=\"A enciclopédia livre\" href=\"//pt.wikipedia.org/\" id=\"js-link-box-pt\" title=\"Português — Wikipédia — A enciclopédia livre\">\n",
      "<strong>Português</strong>\n",
      "<small><bdi dir=\"ltr\">1 048 000+</bdi> <span>artigos</span></small>\n",
      "</a>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    " '''\n",
    "    Outro exemplo. Acessando o elemento class=\"central-featured-lang lang9\"\n",
    "    usando select\n",
    "\n",
    " <div class=\"central-featured-lang lang9\" lang=\"pt\" dir=\"ltr\">\n",
    "        <a id=\"js-link-box-pt\" href=\"//pt.wikipedia.org/\" title=\"Português — Wikipédia — A enciclopédia livre\" class=\"link-box\" data-slogan=\"A enciclopédia livre\">\n",
    "            <strong>Português</strong>\n",
    "            <small>\n",
    "                    <bdi dir=\"ltr\">1&nbsp;048&nbsp;000+</bdi> <span>artigos</span>\n",
    "            </small>\n",
    "        </a>\n",
    "    </div>\n",
    "'''\n",
    "print(bs.select(\".lang9\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"link-box\" data-slogan=\"A enciclopédia livre\" href=\"//pt.wikipedia.org/\" id=\"js-link-box-pt\" title=\"Português — Wikipédia — A enciclopédia livre\">\n",
      "<strong>Português</strong>\n",
      "<small><bdi dir=\"ltr\">1 048 000+</bdi> <span>artigos</span></small>\n",
      "</a>]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Outra maneira de selecionar atributo id sem usar *kwargs. Usando select\n",
    "'''\n",
    "print(bs.select('#js-link-box-pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O servidor não pode ser encontrado !\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Tratamento de exceções\n",
    "    \n",
    "    Lidando com erros\n",
    "\n",
    "    HTTPError -> Erro de servidor\n",
    "    URLError -> Erro de acesso a página\n",
    "'''\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError, URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('https://www.wikipedia90.org') # Simulando URLError\n",
    "\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "\n",
    "except URLError as e:\n",
    "    print(\"O servidor não pode ser encontrado !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "5bb08c390bd9d1f4f3f9ac8562766906130dc5cfd4be55e18928297823c6cf87"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
